{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 204 candidates, totalling 1020 fits\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Accuracy for our training dataset with tuning is : 86.3483%\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(n_neighbors=list(range(1,35)), weights = ['uniform', 'distance'], algorithm = ['ball_tree', 'kd_tree', 'brute'])\n",
    "knn = KNeighborsClassifier(n_jobs = -1)\n",
    "grid = GridSearchCV(knn, param_grid,scoring='accuracy', return_train_score=False, verbose=1, n_jobs= -1)\n",
    "knn_search=grid.fit(X_train, y_train)\n",
    "print(knn_search.best_params_)\n",
    "accuracy = knn_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.4f}%\".format(accuracy) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to train and tune a kNearestNeighbors model with GridSearchCV<br>\n",
    "\n",
    "Finding the parameters which yield the best accuracy for the training dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to train and tune a RandomForest model using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\Hong Yi\\OneDrive\\A-SCHOOL MATERIAL\\polytechnic\\2023_S1\\AA_CA1 Folder\\AIML\\AIML_CA1_Classification\\index_classification.ipynb Cell 69\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hong%20Yi/OneDrive/A-SCHOOL%20MATERIAL/polytechnic/2023_S1/AA_CA1%20Folder/AIML/AIML_CA1_Classification/index_classification.ipynb#Y125sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rfc \u001b[39m=\u001b[39m RandomForestClassifier(n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hong%20Yi/OneDrive/A-SCHOOL%20MATERIAL/polytechnic/2023_S1/AA_CA1%20Folder/AIML/AIML_CA1_Classification/index_classification.ipynb#Y125sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rfc_grid \u001b[39m=\u001b[39m GridSearchCV(rfc, param_grid \u001b[39m=\u001b[39m param_grid, return_train_score\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Hong%20Yi/OneDrive/A-SCHOOL%20MATERIAL/polytechnic/2023_S1/AA_CA1%20Folder/AIML/AIML_CA1_Classification/index_classification.ipynb#Y125sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m rfc_search \u001b[39m=\u001b[39m rfc_grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hong%20Yi/OneDrive/A-SCHOOL%20MATERIAL/polytechnic/2023_S1/AA_CA1%20Folder/AIML/AIML_CA1_Classification/index_classification.ipynb#Y125sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(rfc_search\u001b[39m.\u001b[39mbest_params_)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Hong%20Yi/OneDrive/A-SCHOOL%20MATERIAL/polytechnic/2023_S1/AA_CA1%20Folder/AIML/AIML_CA1_Classification/index_classification.ipynb#Y125sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m accuracy \u001b[39m=\u001b[39m rfc_search\u001b[39m.\u001b[39mbest_score_ \u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n",
      "\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n",
      "\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n",
      "\u001b[0;32m    887\u001b[0m     )\n",
      "\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n",
      "\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n",
      "\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n",
      "\u001b[0;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n",
      "\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n",
      "\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n",
      "\u001b[0;32m    835\u001b[0m         )\n",
      "\u001b[0;32m    836\u001b[0m     )\n",
      "\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n",
      "\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n",
      "\u001b[0;32m    841\u001b[0m         X,\n",
      "\u001b[0;32m    842\u001b[0m         y,\n",
      "\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n",
      "\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n",
      "\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n",
      "\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n",
      "\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n",
      "\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n",
      "\u001b[0;32m    849\u001b[0m     )\n",
      "\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n",
      "\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n",
      "\u001b[0;32m    852\u001b[0m     )\n",
      "\u001b[0;32m    853\u001b[0m )\n",
      "\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m    860\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n",
      "\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n",
      "\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n",
      "\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n",
      "\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n",
      "\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n",
      "\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n",
      "\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n",
      "\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n",
      "\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Hong Yi\\anaconda3\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n",
      "\u001b[0;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n",
      "\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n",
      "\u001b[0;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_est_arr = list(np.arange(1,10))\n",
    "for i in list(np.arange(10,100,10)):n_est_arr.append(i)\n",
    "\n",
    "param_grid = dict(n_estimators= n_est_arr, max_depth= np.arange(1,10,2), max_features =['sqrt', 'log2'])\n",
    "rfc = RandomForestClassifier(n_jobs = -1)\n",
    "rfc_grid = GridSearchCV(rfc, param_grid = param_grid, return_train_score=False, verbose=1, n_jobs= -1)\n",
    "rfc_search = rfc_grid.fit(X_train, y_train)\n",
    "print(rfc_search.best_params_)\n",
    "accuracy = rfc_search.best_score_ *100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.4f}%\".format(accuracy) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to train and tune a SVC model using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 999 candidates, totalling 4995 fits\n",
      "{'C': 97.4}\n",
      "Accuracy for our training dataset with tuning is : 78.8764%\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(C = np.arange(0.1,100,0.1))\n",
    "svc = SVC(max_iter= -1)\n",
    "svc_grid = GridSearchCV(svc, param_grid, verbose = 1, n_jobs= -1)\n",
    "svc_search = svc_grid.fit(X_train, y_train)\n",
    "print(svc_search.best_params_)\n",
    "accuracy = svc_search.best_score_*100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.4f}%\".format(accuracy) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 999 candidates, totalling 4995 fits\n",
      "{'C': 97.4}\n",
      "Accuracy for our training dataset with tuning is : 78.8764%\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(C = np.arange(0.1,100,0.1))\n",
    "svc = SVC(max_iter= -1)\n",
    "svc_grid = GridSearchCV(svc, param_grid, verbose = 1, n_jobs= -1)\n",
    "svc_search = svc_grid.fit(X_train, y_train)\n",
    "print(svc_search.best_params_)\n",
    "accuracy = svc_search.best_score_*100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.4f}%\".format(accuracy) )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to train and tune a Bernoulli Naive Bayes model using GridSearchCV <br>\n",
    "<font size = 2>Note: Despite there being several variants of Naive Bayes classifiers used in Machine Learning, I elected to use the Bernoulli Naive Bayes method, as it is the most appropriate model to use when dealing with binary or Boolean features.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'alpha': 0.901}\n",
      "Accuracy for our training dataset with tuning is : 53.9888%\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(alpha = np.arange(0.001,10,0.1))\n",
    "ber_nb = BernoulliNB()\n",
    "ber_grid = GridSearchCV(ber_nb, param_grid, verbose = 1)\n",
    "ber_search = ber_grid.fit(X_train, y_train)\n",
    "print(ber_search.best_params_)\n",
    "accuracy = ber_search.best_score_*100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.4f}%\".format(accuracy) )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to train and tune a GradientBoostingClassifier model using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "{'learning_rate': 0.5, 'loss': 'exponential', 'max_depth': 8, 'n_estimators': 91}\n",
      "Accuracy for our training dataset with tuning is : 94.9438%\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(loss = [\"exponential\"], learning_rate = np.arange(0.1, 1, 0.10), n_estimators = np.arange(1, 100, 10), max_depth = np.arange(1,11,1))\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_grid = GridSearchCV(gbc, param_grid, verbose = 1, n_jobs= -1)\n",
    "gbc_search = gbc_grid.fit(X_train, y_train)\n",
    "print(gbc_search.best_params_)\n",
    "accuracy = gbc_search.best_score_*100\n",
    "print(\"Accuracy for our training dataset with tuning is : {:.4f}%\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
